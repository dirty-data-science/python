{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Machine learning with missing values\n\nHere we use simulated data to understanding the fundamentals of statistical\nlearning with missing values.\n\nThis notebook reveals why a HistGradientBoostingRegressor (\n:class:`sklearn.ensemble.HistGradientBoostingRegressor` ) is a choice to\npredict with missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (5, 4) # Smaller default figure size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The fully-observed data: a toy regression problem\n\nWe consider a simple regression problem where X (the data) is bivariate\ngaussian, and y (the prediction target)  is a linear function of the first\ncoordinate, with noise.\n\n### The data-generating mechanism\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_without_missing_values(n_samples, rng=42):\n    mean = [0, 0]\n    cov = [[1, 0.5], [0.5, 1]]\n    if not isinstance(rng, np.random.RandomState):\n        rng = np.random.RandomState(rng)\n    X = rng.multivariate_normal(mean, cov, size=n_samples)\n\n    epsilon = 0.1 * rng.randn(n_samples)\n    y = X[:, 0] + epsilon\n\n    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick plot reveals what the data looks like\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nX_full, y_full = generate_without_missing_values(500)\nplt.scatter(X_full[:, 0], X_full[:, 1], c=y_full)\nplt.colorbar(label='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing completely at random setting\n\nWe now consider missing completely at random settings (a special case\nof missing at random).\n\n### The missing-values mechanism\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_mcar(n_samples, missing_rate=0.2, rng=42):\n    X, y = generate_without_missing_values(n_samples, rng=rng)\n    if not isinstance(rng, np.random.RandomState):\n        rng = np.random.RandomState(rng)\n\n    M = rng.binomial(1, missing_rate, (n_samples, 2))\n    np.putmask(X, M, np.nan)\n\n    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick plot to look at the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = generate_mcar(500, missing_rate=.5)\n\nplt.figure()\nplt.scatter(X_full[:, 0], X_full[:, 1], color='.8', ec='.5',\n            label='All data')\nplt.colorbar(label='y')\nplt.scatter(X[:, 0], X[:, 1], c=y, label='Fully observed')\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the distribution of the fully-observed data is the same\nthan that of the original data\n\n### Building a predictive model: imputation and simple model\n\nGiven that the relationship between the fully-observed X and y is a\nlinear relationship, it seems natural to use a linear model for\nprediction, which must be adapted to missing values using imputation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import RidgeCV # Good default linear model\nfrom sklearn.impute import IterativeImputive # Good imputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing not at random: censoring\n\nWe now consider missing not at random settings, in particular\nself-masking or censoring, where large values are more likely to be\nmissing.\n\n### The missing-values mechanism\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_censored(n_samples, missing_rate=0.2, rng=42):\n    X, y = generate_without_missing_values(n_samples, rng=rng)\n    if not isinstance(rng, np.random.RandomState):\n        rng = np.random.RandomState(rng)\n\n    B = np.random.binomial(1, 2 * missing_rate, (n_samples, 2))\n    M = (X > 0.5) * B\n\n    np.putmask(X, M, np.nan)\n\n    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick plot to look at the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = generate_censored(500, missing_rate=.4)\n\nplt.figure()\nplt.scatter(X_full[:, 0], X_full[:, 1], color='.8', ec='.5',\n            label='All data')\nplt.colorbar(label='y')\nplt.scatter(X[:, 0], X[:, 1], c=y, label='Fully observed')\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the full-observed data does not reflect well at all the\ndistribution of all the data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a predictor for the fully-observed case\n\nLet us go back to the \"easy\" case of the missing completely at random\nsettings with plenty of data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 10000\n\nX, y = generate_mcar(n_samples, missing_rate=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we have been able to train a predictive model that works on\nfully-observed data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_full, y_full = generate_without_missing_values(n_samples)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}