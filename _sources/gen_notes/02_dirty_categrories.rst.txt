
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "gen_notes/02_dirty_categrories.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_gen_notes_02_dirty_categrories.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_gen_notes_02_dirty_categrories.py:


========================================================
Dirty categories: learning with non normalized entries
========================================================

Including strings that represent categories often calls for much data
preparation. In particular categories may appear with many morphological
variants, when they have been manually input, or assembled from diverse
sources.

Including such a column in a learning pipeline as a standard categorical
colum leads to categories with very high cardinalities and can loose
information on which categories are similar.

Here we look at a dataset on wages [#]_ where the column *Employee
Position Title* contains dirty categories.

.. [#] https://catalog.data.gov/dataset/employee-salaries-2016

We investigate encodings to include such compare different categorical
encodings for the dirty column to predict the *Current Annual Salary*,
using gradient boosted trees.

.. GENERATED FROM PYTHON SOURCE LINES 27-34

The data
========

Data Importing and preprocessing
--------------------------------

We first download the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 35-39

.. code-block:: default

    from dirty_cat.datasets import fetch_employee_salaries
    employee_salaries = fetch_employee_salaries()
    print(employee_salaries['DESCR'])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Annual salary information including gross pay and overtime pay for all active, permanent employees of Montgomery County, MD paid in calendar year 2016. This information will be published annually each year.

    Downloaded from openml.org.




.. GENERATED FROM PYTHON SOURCE LINES 40-41

Then we load it:

.. GENERATED FROM PYTHON SOURCE LINES 41-45

.. code-block:: default

    import pandas as pd
    df = employee_salaries['data'].copy()
    df






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>full_name</th>
          <th>gender</th>
          <th>2016_gross_pay_received</th>
          <th>2016_overtime_pay</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>underfilled_job_title</th>
          <th>date_first_hired</th>
          <th>year_first_hired</th>
          <th>Current Annual Salary</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>Aarhus, Pam J.</td>
          <td>F</td>
          <td>71225.98</td>
          <td>416.10</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>None</td>
          <td>09/22/1986</td>
          <td>1986.0</td>
          <td>69222.18</td>
        </tr>
        <tr>
          <th>1</th>
          <td>Aaron, David J.</td>
          <td>M</td>
          <td>103088.48</td>
          <td>3326.19</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>None</td>
          <td>09/12/1988</td>
          <td>1988.0</td>
          <td>97392.47</td>
        </tr>
        <tr>
          <th>2</th>
          <td>Aaron, Marsha M.</td>
          <td>F</td>
          <td>107000.24</td>
          <td>1353.32</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>None</td>
          <td>11/19/1989</td>
          <td>1989.0</td>
          <td>104717.28</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Ababio, Godfred A.</td>
          <td>M</td>
          <td>57819.04</td>
          <td>3423.07</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>None</td>
          <td>05/05/2014</td>
          <td>2014.0</td>
          <td>52734.57</td>
        </tr>
        <tr>
          <th>4</th>
          <td>Ababu, Essayas</td>
          <td>M</td>
          <td>95815.17</td>
          <td>NaN</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>None</td>
          <td>03/05/2007</td>
          <td>2007.0</td>
          <td>93396.00</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>Zurita, Justina</td>
          <td>F</td>
          <td>58154.47</td>
          <td>NaN</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>None</td>
          <td>11/03/2015</td>
          <td>2015.0</td>
          <td>72094.53</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>Zuspan, Diane M.</td>
          <td>F</td>
          <td>173173.01</td>
          <td>956.97</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>None</td>
          <td>11/28/1988</td>
          <td>1988.0</td>
          <td>169543.85</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>Zwerdling, David</td>
          <td>M</td>
          <td>104238.18</td>
          <td>NaN</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>None</td>
          <td>04/30/2001</td>
          <td>2001.0</td>
          <td>102736.52</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>Zyontz, Jeffrey L.</td>
          <td>M</td>
          <td>149105.25</td>
          <td>NaN</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>None</td>
          <td>09/05/2006</td>
          <td>2006.0</td>
          <td>153747.50</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>Zywiolek, Tim R.</td>
          <td>M</td>
          <td>74975.53</td>
          <td>NaN</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>None</td>
          <td>01/30/2012</td>
          <td>2012.0</td>
          <td>75484.08</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows × 13 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 46-47

Now, let's carry out some basic preprocessing:

.. GENERATED FROM PYTHON SOURCE LINES 47-53

.. code-block:: default

    df['Date First Hired'] = pd.to_datetime(df['date_first_hired'])
    df['Year First Hired'] = df['Date First Hired'].apply(lambda x: x.year)
    # drop rows with NaN in gender
    df.dropna(subset=['gender'], inplace=True)









.. GENERATED FROM PYTHON SOURCE LINES 54-55

First we extract the target

.. GENERATED FROM PYTHON SOURCE LINES 55-59

.. code-block:: default


    target_column = 'Current Annual Salary'
    y = df[target_column].values.ravel()








.. GENERATED FROM PYTHON SOURCE LINES 60-68

Assembling a machine-learning pipeline that encodes the data
=============================================================

Choosing columns
-----------------

For clean categorical columns, we will use one hot encoding to
transform them:

.. GENERATED FROM PYTHON SOURCE LINES 69-76

.. code-block:: default


    clean_columns = {
        'gender': 'one-hot',
        'department_name': 'one-hot',
        'assignment_category': 'one-hot',
        'Year First Hired': 'numerical'}








.. GENERATED FROM PYTHON SOURCE LINES 77-79

We then choose the categorical encoding methods we want to benchmark
and the dirty categorical variable:

.. GENERATED FROM PYTHON SOURCE LINES 79-85

.. code-block:: default


    encoding_methods = ['one-hot', 'target', 'similarity', 'minhash',
                        'gap']
    dirty_column = 'employee_position_title'









.. GENERATED FROM PYTHON SOURCE LINES 86-89

The learning pipeline
----------------------------
The encoders for both clean and dirty data are first imported:

.. GENERATED FROM PYTHON SOURCE LINES 89-131

.. code-block:: default


    from sklearn.preprocessing import FunctionTransformer
    from sklearn.preprocessing import OneHotEncoder
    from dirty_cat import SimilarityEncoder, TargetEncoder, MinHashEncoder,\
        GapEncoder

    # for scikit-learn 0.24 we need to require the experimental feature
    from sklearn.experimental import enable_hist_gradient_boosting  # noqa
    # now you can import normally from ensemble
    from sklearn.ensemble import HistGradientBoostingRegressor

    encoders_dict = {
        'one-hot': OneHotEncoder(handle_unknown='ignore', sparse=False),
        'similarity': SimilarityEncoder(similarity='ngram'),
        'target': TargetEncoder(handle_unknown='ignore'),
        'minhash': MinHashEncoder(n_components=100),
        'gap': GapEncoder(n_components=100),
        'numerical': FunctionTransformer(None)}

    # We then create a function that takes one key of our ``encoders_dict``,
    # returns a pipeline object with the associated encoder,
    # as well as a gradient-boosting regressor

    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import make_pipeline


    def assemble_pipeline(encoding_method):
        # static transformers from the other columns
        transformers = [(enc + '_' + col, encoders_dict[enc], [col])
                        for col, enc in clean_columns.items()]
        # adding the encoded column
        transformers += [(encoding_method, encoders_dict[encoding_method],
                          [dirty_column])]
        pipeline = make_pipeline(
            # Use ColumnTransformer to combine the features
            ColumnTransformer(transformers=transformers, remainder='drop'),
            HistGradientBoostingRegressor()
        )
        return pipeline









.. GENERATED FROM PYTHON SOURCE LINES 132-137

Comparing different encoding for supervised learning
-----------------------------------------------------
Eventually, we loop over the different encoding methods,
instantiate each time a new pipeline, fit it
and store the returned cross-validation score:

.. GENERATED FROM PYTHON SOURCE LINES 137-151

.. code-block:: default


    from sklearn.model_selection import cross_val_score
    import numpy as np

    all_scores = dict()

    for method in encoding_methods:
        pipeline = assemble_pipeline(method)
        scores = cross_val_score(pipeline, df, y)
        print('{} encoding'.format(method))
        print('r2 score:  mean: {:.3f}; std: {:.3f}\n'.format(
            np.mean(scores), np.std(scores)))
        all_scores[method] = scores





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    one-hot encoding
    r2 score:  mean: 0.776; std: 0.028

    target encoding
    r2 score:  mean: 0.842; std: 0.030

    similarity encoding
    r2 score:  mean: 0.923; std: 0.014

    minhash encoding
    r2 score:  mean: 0.919; std: 0.012

    gap encoding
    r2 score:  mean: 0.907; std: 0.014





.. GENERATED FROM PYTHON SOURCE LINES 152-155

Plotting the results
--------------------
Finally, we plot the scores on a boxplot:

.. GENERATED FROM PYTHON SOURCE LINES 155-165

.. code-block:: default


    import seaborn
    import matplotlib.pyplot as plt
    plt.figure(figsize=(4, 3))
    ax = seaborn.boxplot(data=pd.DataFrame(all_scores), orient='h')
    plt.ylabel('Encoding', size=20)
    plt.xlabel('Prediction accuracy     ', size=20)
    plt.yticks(size=20)
    plt.tight_layout()




.. image:: /gen_notes/images/sphx_glr_02_dirty_categrories_001.png
    :alt: 02 dirty categrories
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 166-177

The clear trend is that encoders that use the string form
of the category (similarity, minhash, and gap) perform better than
those that discard it.

SimilarityEncoder is the best performer, but it is less scalable on big
data than MinHashEncoder and GapEncoder. The most scalable encoder is
the MinHashEncoder. GapEncoder, on the other hand, has the benefit that
it provides interpretable features (see :ref:`sphx_glr_auto_examples_04_feature_interpretation_gap_encoder.py`)

|


.. GENERATED FROM PYTHON SOURCE LINES 179-201

Automatic vectorization
========================

.. |SV| replace::
    :class:`~dirty_cat.SuperVectorizer`

.. |OneHotEncoder| replace::
    :class:`~sklearn.preprocessing.OneHotEncoder`

.. |ColumnTransformer| replace::
    :class:`~sklearn.compose.ColumnTransformer`

.. |RandomForestRegressor| replace::
    :class:`~sklearn.ensemble.RandomForestRegressor`

.. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`

.. |permutation importances| replace::
    :func:`~sklearn.inspection.permutation_importance`

Let's start again from the raw data, but this time well use an
automated way of encoding the data

.. GENERATED FROM PYTHON SOURCE LINES 201-204

.. code-block:: default

    X = employee_salaries['data']
    y = employee_salaries['target']








.. GENERATED FROM PYTHON SOURCE LINES 205-206

We'll drop a few columns we don't want

.. GENERATED FROM PYTHON SOURCE LINES 206-218

.. code-block:: default

    X.drop(
        [
            'Current Annual Salary',  # Too linked with target
            'full_name',  # Not relevant to the analysis
            '2016_gross_pay_received',  # Too linked with target
            '2016_overtime_pay',  # Too linked with target
            'date_first_hired'  # Redundant with "year_first_hired"
        ],
        axis=1,
        inplace=True
    )








.. GENERATED FROM PYTHON SOURCE LINES 219-220

We have a fairly complex and heterogeneous dataframe:

.. GENERATED FROM PYTHON SOURCE LINES 220-222

.. code-block:: default

    X






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>gender</th>
          <th>department</th>
          <th>department_name</th>
          <th>division</th>
          <th>assignment_category</th>
          <th>employee_position_title</th>
          <th>underfilled_job_title</th>
          <th>year_first_hired</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>F</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>MSB Information Mgmt and Tech Division Records...</td>
          <td>Fulltime-Regular</td>
          <td>Office Services Coordinator</td>
          <td>None</td>
          <td>1986.0</td>
        </tr>
        <tr>
          <th>1</th>
          <td>M</td>
          <td>POL</td>
          <td>Department of Police</td>
          <td>ISB Major Crimes Division Fugitive Section</td>
          <td>Fulltime-Regular</td>
          <td>Master Police Officer</td>
          <td>None</td>
          <td>1988.0</td>
        </tr>
        <tr>
          <th>2</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Adult Protective and Case Management Services</td>
          <td>Fulltime-Regular</td>
          <td>Social Worker IV</td>
          <td>None</td>
          <td>1989.0</td>
        </tr>
        <tr>
          <th>3</th>
          <td>M</td>
          <td>COR</td>
          <td>Correction and Rehabilitation</td>
          <td>PRRS Facility and Security</td>
          <td>Fulltime-Regular</td>
          <td>Resident Supervisor II</td>
          <td>None</td>
          <td>2014.0</td>
        </tr>
        <tr>
          <th>4</th>
          <td>M</td>
          <td>HCA</td>
          <td>Department of Housing and Community Affairs</td>
          <td>Affordable Housing Programs</td>
          <td>Fulltime-Regular</td>
          <td>Planning Specialist III</td>
          <td>None</td>
          <td>2007.0</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>9223</th>
          <td>F</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>School Based Health Centers</td>
          <td>Fulltime-Regular</td>
          <td>Community Health Nurse II</td>
          <td>None</td>
          <td>2015.0</td>
        </tr>
        <tr>
          <th>9224</th>
          <td>F</td>
          <td>FRS</td>
          <td>Fire and Rescue Services</td>
          <td>Human Resources Division</td>
          <td>Fulltime-Regular</td>
          <td>Fire/Rescue Division Chief</td>
          <td>None</td>
          <td>1988.0</td>
        </tr>
        <tr>
          <th>9225</th>
          <td>M</td>
          <td>HHS</td>
          <td>Department of Health and Human Services</td>
          <td>Child and Adolescent Mental Health Clinic Serv...</td>
          <td>Parttime-Regular</td>
          <td>Medical Doctor IV - Psychiatrist</td>
          <td>None</td>
          <td>2001.0</td>
        </tr>
        <tr>
          <th>9226</th>
          <td>M</td>
          <td>CCL</td>
          <td>County Council</td>
          <td>Council Central Staff</td>
          <td>Fulltime-Regular</td>
          <td>Manager II</td>
          <td>None</td>
          <td>2006.0</td>
        </tr>
        <tr>
          <th>9227</th>
          <td>M</td>
          <td>DLC</td>
          <td>Department of Liquor Control</td>
          <td>Licensure, Regulation and Education</td>
          <td>Fulltime-Regular</td>
          <td>Alcohol/Tobacco Enforcement Specialist II</td>
          <td>None</td>
          <td>2012.0</td>
        </tr>
      </tbody>
    </table>
    <p>9228 rows × 8 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 223-225

The challenge is to turn this dataframe into a form suited for
machine learning.

.. GENERATED FROM PYTHON SOURCE LINES 227-233

Using the SuperVectorizer in a supervised-learning pipeline
------------------------------------------------------------

Assembling the |SV| in a pipeline with a powerful learner,
such as gradient boosted trees, gives **a machine-learning method that
can be readily applied to the dataframe**.

.. GENERATED FROM PYTHON SOURCE LINES 233-242

.. code-block:: default


    # The supervectorizer requires dirty_cat 0.2.0a1
    from dirty_cat import SuperVectorizer

    pipeline = make_pipeline(
        SuperVectorizer(auto_cast=True),
        HistGradientBoostingRegressor()
    )








.. GENERATED FROM PYTHON SOURCE LINES 243-244

Let's perform a cross-validation to see how well this model predicts

.. GENERATED FROM PYTHON SOURCE LINES 244-253

.. code-block:: default


    from sklearn.model_selection import cross_val_score
    scores = cross_val_score(pipeline, X, y, scoring='r2')

    import numpy as np
    print(f'{scores=}')
    print(f'mean={np.mean(scores)}')
    print(f'std={np.std(scores)}')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    scores=array([0.87298866, 0.8558411 , 0.89355612, 0.91518761, 0.91688305])
    mean=0.8908913085046242
    std=0.023757122152343244




.. GENERATED FROM PYTHON SOURCE LINES 254-257

The prediction perform here is pretty much as good as above
but the code here is much simpler as it does not involve specifying
columns manually.

.. GENERATED FROM PYTHON SOURCE LINES 259-264

Analyzing the features created
-------------------------------

Let us perform the same workflow, but without the `Pipeline`, so we can
analyze its mechanisms along the way.

.. GENERATED FROM PYTHON SOURCE LINES 264-266

.. code-block:: default

    sup_vec = SuperVectorizer(auto_cast=True)








.. GENERATED FROM PYTHON SOURCE LINES 267-268

We split the data between train and test, and transform them:

.. GENERATED FROM PYTHON SOURCE LINES 268-276

.. code-block:: default

    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, random_state=42
    )

    X_train_enc = sup_vec.fit_transform(X_train, y_train)
    X_test_enc = sup_vec.transform(X_test)








.. GENERATED FROM PYTHON SOURCE LINES 277-281

Inspecting the features created
.................................
Once it has been trained on data,
we can print the transformers and the columns assignment it creates:

.. GENERATED FROM PYTHON SOURCE LINES 281-284

.. code-block:: default


    sup_vec.transformers_





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    [('high_card_str', GapEncoder(), ['division', 'employee_position_title', 'underfilled_job_title']), ('low_card_cat', OneHotEncoder(), ['gender', 'assignment_category']), ('high_card_cat', GapEncoder(), ['department', 'department_name']), ('remainder', 'passthrough', [7])]



.. GENERATED FROM PYTHON SOURCE LINES 285-298

This is what is being passed to the |ColumnTransformer| under the hood.
If you're familiar with how the later works, it should be very intuitive.
We can notice it classified the columns "gender" and "assignment_category"
as low cardinality string variables.
A |OneHotEncoder| will be applied to these columns.

The vectorizer actually makes the difference between string variables
(data type ``object`` and ``string``) and categorical variables
(data type ``category``).

Next, we can have a look at the encoded feature names.

Before encoding:

.. GENERATED FROM PYTHON SOURCE LINES 298-300

.. code-block:: default

    X.columns.to_list()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    ['gender', 'department', 'department_name', 'division', 'assignment_category', 'employee_position_title', 'underfilled_job_title', 'year_first_hired']



.. GENERATED FROM PYTHON SOURCE LINES 301-302

After encoding (we only plot the first 8 feature names):

.. GENERATED FROM PYTHON SOURCE LINES 302-305

.. code-block:: default

    feature_names = sup_vec.get_feature_names()
    feature_names[:8]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    ['division: landlord, toddlers, programs', 'division: station, region, mc311', 'division: nicholson, security, director', 'division: eligibility, facilities, highway', 'division: district, patrol, squad', 'division: gaithersburg, supports, support', 'division: commuter, duplicating, special', 'division: adolescent, health, behavioral']



.. GENERATED FROM PYTHON SOURCE LINES 306-312

As we can see, it created a new column for each unique value.
This is because we used |SE| on the column "division",
which was classified as a high cardinality string variable.
(default values, see |SV|'s docstring).

In total, we have reasonnable number of encoded columns.

.. GENERATED FROM PYTHON SOURCE LINES 312-315

.. code-block:: default

    len(feature_names)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    56



.. GENERATED FROM PYTHON SOURCE LINES 316-328

Feature importance in the statistical model
---------------------------------------------

In this section, we will train a regressor, and plot the feature importances

.. topic:: Note:

   To minimize compute time, use the feature importances computed by the
   |RandomForestRegressor|, but you should prefer |permutation importances|
   instead (which are less subject to biases)

First, let's train the |RandomForestRegressor|,

.. GENERATED FROM PYTHON SOURCE LINES 328-334

.. code-block:: default


    from sklearn.ensemble import RandomForestRegressor
    regressor = RandomForestRegressor()
    regressor.fit(X_train_enc, y_train)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    RandomForestRegressor()



.. GENERATED FROM PYTHON SOURCE LINES 335-336

Retreiving the feature importances

.. GENERATED FROM PYTHON SOURCE LINES 336-346

.. code-block:: default

    importances = regressor.feature_importances_
    std = np.std(
        [
            tree.feature_importances_
            for tree in regressor.estimators_
        ],
        axis=0
    )
    indices = np.argsort(importances)[::-1]








.. GENERATED FROM PYTHON SOURCE LINES 347-348

Plotting the results:

.. GENERATED FROM PYTHON SOURCE LINES 348-360

.. code-block:: default


    import matplotlib.pyplot as plt
    plt.figure(figsize=(12, 9))
    plt.title("Feature importances")
    n = 20
    n_indices = indices[:n]
    labels = np.array(feature_names)[n_indices]
    plt.barh(range(n), importances[n_indices], color="b", yerr=std[n_indices])
    plt.yticks(range(n), labels, size=15)
    plt.tight_layout(pad=1)
    plt.show()




.. image:: /gen_notes/images/sphx_glr_02_dirty_categrories_002.png
    :alt: Feature importances
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 361-372

We can deduce from this data that the three factors that define the
most the salary are: being hired for a long time, being a manager, and
having a permanent, full-time job :).


.. topic:: The SuperVectorizer automates preprocessing

  As this notebook demonstrates, many preprocessing steps can be
  automated by the |SV|, and the resulting pipeline can still be
  inspected, even with non-normalized entries.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  1.433 seconds)


.. _sphx_glr_download_gen_notes_02_dirty_categrories.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/dirty-data-science/python/gh-pages?filepath=notes/gen_notes/02_dirty_categrories.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 02_dirty_categrories.py <02_dirty_categrories.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 02_dirty_categrories.ipynb <02_dirty_categrories.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
