{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dirty categories: learning with non normalized entries\n",
    "\n",
    "Including strings that represent categories often calls for much data\n",
    "preparation. In particular categories may appear with many morphological\n",
    "variants, when they have been manually input, or assembled from diverse\n",
    "sources.\n",
    "\n",
    "Including such a column in a learning pipeline as a standard categorical\n",
    "colum leads to categories with very high cardinalities and can loose\n",
    "information on which categories are similar.\n",
    "\n",
    "Here we look at a dataset on wages [#]_ where the column *Employee\n",
    "Position Title* contains dirty categories.\n",
    "\n",
    ".. [#] https://catalog.data.gov/dataset/employee-salaries-2016\n",
    "\n",
    "We investigate encodings to include such compare different categorical\n",
    "encodings for the dirty column to predict the *Current Annual Salary*,\n",
    "using gradient boosted trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "### Data Importing and preprocessing\n",
    "\n",
    "We first download the dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual salary information including gross pay and overtime pay for all active, permanent employees of Montgomery County, MD paid in calendar year 2016. This information will be published annually each year.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "from dirty_cat.datasets import fetch_employee_salaries\n",
    "employee_salaries = fetch_employee_salaries()\n",
    "print(employee_salaries['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>2016_gross_pay_received</th>\n",
       "      <th>2016_overtime_pay</th>\n",
       "      <th>department</th>\n",
       "      <th>department_name</th>\n",
       "      <th>division</th>\n",
       "      <th>assignment_category</th>\n",
       "      <th>employee_position_title</th>\n",
       "      <th>underfilled_job_title</th>\n",
       "      <th>date_first_hired</th>\n",
       "      <th>year_first_hired</th>\n",
       "      <th>Current Annual Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aarhus, Pam J.</td>\n",
       "      <td>F</td>\n",
       "      <td>71225.98</td>\n",
       "      <td>416.10</td>\n",
       "      <td>POL</td>\n",
       "      <td>Department of Police</td>\n",
       "      <td>MSB Information Mgmt and Tech Division Records...</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Office Services Coordinator</td>\n",
       "      <td>None</td>\n",
       "      <td>09/22/1986</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>69222.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron, David J.</td>\n",
       "      <td>M</td>\n",
       "      <td>103088.48</td>\n",
       "      <td>3326.19</td>\n",
       "      <td>POL</td>\n",
       "      <td>Department of Police</td>\n",
       "      <td>ISB Major Crimes Division Fugitive Section</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Master Police Officer</td>\n",
       "      <td>None</td>\n",
       "      <td>09/12/1988</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>97392.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron, Marsha M.</td>\n",
       "      <td>F</td>\n",
       "      <td>107000.24</td>\n",
       "      <td>1353.32</td>\n",
       "      <td>HHS</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>Adult Protective and Case Management Services</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Social Worker IV</td>\n",
       "      <td>None</td>\n",
       "      <td>11/19/1989</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>104717.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ababio, Godfred A.</td>\n",
       "      <td>M</td>\n",
       "      <td>57819.04</td>\n",
       "      <td>3423.07</td>\n",
       "      <td>COR</td>\n",
       "      <td>Correction and Rehabilitation</td>\n",
       "      <td>PRRS Facility and Security</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Resident Supervisor II</td>\n",
       "      <td>None</td>\n",
       "      <td>05/05/2014</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>52734.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ababu, Essayas</td>\n",
       "      <td>M</td>\n",
       "      <td>95815.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCA</td>\n",
       "      <td>Department of Housing and Community Affairs</td>\n",
       "      <td>Affordable Housing Programs</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Planning Specialist III</td>\n",
       "      <td>None</td>\n",
       "      <td>03/05/2007</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>93396.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9223</th>\n",
       "      <td>Zurita, Justina</td>\n",
       "      <td>F</td>\n",
       "      <td>58154.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHS</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>School Based Health Centers</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Community Health Nurse II</td>\n",
       "      <td>None</td>\n",
       "      <td>11/03/2015</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>72094.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9224</th>\n",
       "      <td>Zuspan, Diane M.</td>\n",
       "      <td>F</td>\n",
       "      <td>173173.01</td>\n",
       "      <td>956.97</td>\n",
       "      <td>FRS</td>\n",
       "      <td>Fire and Rescue Services</td>\n",
       "      <td>Human Resources Division</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Fire/Rescue Division Chief</td>\n",
       "      <td>None</td>\n",
       "      <td>11/28/1988</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>169543.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>Zwerdling, David</td>\n",
       "      <td>M</td>\n",
       "      <td>104238.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHS</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>Child and Adolescent Mental Health Clinic Serv...</td>\n",
       "      <td>Parttime-Regular</td>\n",
       "      <td>Medical Doctor IV - Psychiatrist</td>\n",
       "      <td>None</td>\n",
       "      <td>04/30/2001</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>102736.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9226</th>\n",
       "      <td>Zyontz, Jeffrey L.</td>\n",
       "      <td>M</td>\n",
       "      <td>149105.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCL</td>\n",
       "      <td>County Council</td>\n",
       "      <td>Council Central Staff</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Manager II</td>\n",
       "      <td>None</td>\n",
       "      <td>09/05/2006</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>153747.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>Zywiolek, Tim R.</td>\n",
       "      <td>M</td>\n",
       "      <td>74975.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DLC</td>\n",
       "      <td>Department of Liquor Control</td>\n",
       "      <td>Licensure, Regulation and Education</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Alcohol/Tobacco Enforcement Specialist II</td>\n",
       "      <td>None</td>\n",
       "      <td>01/30/2012</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>75484.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9228 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               full_name gender  2016_gross_pay_received  2016_overtime_pay  \\\n",
       "0         Aarhus, Pam J.      F                 71225.98             416.10   \n",
       "1        Aaron, David J.      M                103088.48            3326.19   \n",
       "2       Aaron, Marsha M.      F                107000.24            1353.32   \n",
       "3     Ababio, Godfred A.      M                 57819.04            3423.07   \n",
       "4         Ababu, Essayas      M                 95815.17                NaN   \n",
       "...                  ...    ...                      ...                ...   \n",
       "9223     Zurita, Justina      F                 58154.47                NaN   \n",
       "9224    Zuspan, Diane M.      F                173173.01             956.97   \n",
       "9225    Zwerdling, David      M                104238.18                NaN   \n",
       "9226  Zyontz, Jeffrey L.      M                149105.25                NaN   \n",
       "9227    Zywiolek, Tim R.      M                 74975.53                NaN   \n",
       "\n",
       "     department                              department_name  \\\n",
       "0           POL                         Department of Police   \n",
       "1           POL                         Department of Police   \n",
       "2           HHS      Department of Health and Human Services   \n",
       "3           COR                Correction and Rehabilitation   \n",
       "4           HCA  Department of Housing and Community Affairs   \n",
       "...         ...                                          ...   \n",
       "9223        HHS      Department of Health and Human Services   \n",
       "9224        FRS                     Fire and Rescue Services   \n",
       "9225        HHS      Department of Health and Human Services   \n",
       "9226        CCL                               County Council   \n",
       "9227        DLC                 Department of Liquor Control   \n",
       "\n",
       "                                               division assignment_category  \\\n",
       "0     MSB Information Mgmt and Tech Division Records...    Fulltime-Regular   \n",
       "1            ISB Major Crimes Division Fugitive Section    Fulltime-Regular   \n",
       "2         Adult Protective and Case Management Services    Fulltime-Regular   \n",
       "3                            PRRS Facility and Security    Fulltime-Regular   \n",
       "4                           Affordable Housing Programs    Fulltime-Regular   \n",
       "...                                                 ...                 ...   \n",
       "9223                        School Based Health Centers    Fulltime-Regular   \n",
       "9224                           Human Resources Division    Fulltime-Regular   \n",
       "9225  Child and Adolescent Mental Health Clinic Serv...    Parttime-Regular   \n",
       "9226                              Council Central Staff    Fulltime-Regular   \n",
       "9227                Licensure, Regulation and Education    Fulltime-Regular   \n",
       "\n",
       "                        employee_position_title underfilled_job_title  \\\n",
       "0                   Office Services Coordinator                  None   \n",
       "1                         Master Police Officer                  None   \n",
       "2                              Social Worker IV                  None   \n",
       "3                        Resident Supervisor II                  None   \n",
       "4                       Planning Specialist III                  None   \n",
       "...                                         ...                   ...   \n",
       "9223                  Community Health Nurse II                  None   \n",
       "9224                 Fire/Rescue Division Chief                  None   \n",
       "9225           Medical Doctor IV - Psychiatrist                  None   \n",
       "9226                                 Manager II                  None   \n",
       "9227  Alcohol/Tobacco Enforcement Specialist II                  None   \n",
       "\n",
       "     date_first_hired  year_first_hired  Current Annual Salary  \n",
       "0          09/22/1986            1986.0               69222.18  \n",
       "1          09/12/1988            1988.0               97392.47  \n",
       "2          11/19/1989            1989.0              104717.28  \n",
       "3          05/05/2014            2014.0               52734.57  \n",
       "4          03/05/2007            2007.0               93396.00  \n",
       "...               ...               ...                    ...  \n",
       "9223       11/03/2015            2015.0               72094.53  \n",
       "9224       11/28/1988            1988.0              169543.85  \n",
       "9225       04/30/2001            2001.0              102736.52  \n",
       "9226       09/05/2006            2006.0              153747.50  \n",
       "9227       01/30/2012            2012.0               75484.08  \n",
       "\n",
       "[9228 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = employee_salaries['data'].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's carry out some basic preprocessing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date First Hired'] = pd.to_datetime(df['date_first_hired'])\n",
    "df['Year First Hired'] = df['Date First Hired'].apply(lambda x: x.year)\n",
    "# drop rows with NaN in gender\n",
    "df.dropna(subset=['gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Current Annual Salary'\n",
    "y = df[target_column].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling a machine-learning pipeline that encodes the data\n",
    "\n",
    "### Choosing columns\n",
    "\n",
    "For clean categorical columns, we will use one hot encoding to\n",
    "transform them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_columns = {\n",
    "    'gender': 'one-hot',\n",
    "    'department_name': 'one-hot',\n",
    "    'assignment_category': 'one-hot',\n",
    "    'Year First Hired': 'numerical'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then choose the categorical encoding methods we want to benchmark\n",
    "and the dirty categorical variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_methods = ['one-hot', 'target', 'similarity', 'minhash',\n",
    "                    'gap']\n",
    "dirty_column = 'employee_position_title'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The learning pipeline\n",
    "The encoders for both clean and dirty data are first imported:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from dirty_cat import SimilarityEncoder, TargetEncoder, MinHashEncoder,\\\n",
    "    GapEncoder\n",
    "\n",
    "# for scikit-learn 0.24 we need to require the experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "encoders_dict = {\n",
    "    'one-hot': OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
    "    'similarity': SimilarityEncoder(similarity='ngram'),\n",
    "    'target': TargetEncoder(handle_unknown='ignore'),\n",
    "    'minhash': MinHashEncoder(n_components=100),\n",
    "    'gap': GapEncoder(n_components=100),\n",
    "    'numerical': FunctionTransformer(None)}\n",
    "\n",
    "# We then create a function that takes one key of our ``encoders_dict``,\n",
    "# returns a pipeline object with the associated encoder,\n",
    "# as well as a gradient-boosting regressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def assemble_pipeline(encoding_method):\n",
    "    # static transformers from the other columns\n",
    "    transformers = [(enc + '_' + col, encoders_dict[enc], [col])\n",
    "                    for col, enc in clean_columns.items()]\n",
    "    # adding the encoded column\n",
    "    transformers += [(encoding_method, encoders_dict[encoding_method],\n",
    "                      [dirty_column])]\n",
    "    pipeline = make_pipeline(\n",
    "        # Use ColumnTransformer to combine the features\n",
    "        ColumnTransformer(transformers=transformers, remainder='drop'),\n",
    "        HistGradientBoostingRegressor()\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different encoding for supervised learning\n",
    "Eventually, we loop over the different encoding methods,\n",
    "instantiate each time a new pipeline, fit it\n",
    "and store the returned cross-validation score:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "all_scores = dict()\n",
    "\n",
    "for method in encoding_methods:\n",
    "    pipeline = assemble_pipeline(method)\n",
    "    scores = cross_val_score(pipeline, df, y)\n",
    "    print('{} encoding'.format(method))\n",
    "    print('r2 score:  mean: {:.3f}; std: {:.3f}\\n'.format(\n",
    "        np.mean(scores), np.std(scores)))\n",
    "    all_scores[method] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results\n",
    "Finally, we plot the scores on a boxplot:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 3))\n",
    "ax = seaborn.boxplot(data=pd.DataFrame(all_scores), orient='h')\n",
    "plt.ylabel('Encoding', size=20)\n",
    "plt.xlabel('Prediction accuracy     ', size=20)\n",
    "plt.yticks(size=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clear trend is that encoders that use the string form\n",
    "of the category (similarity, minhash, and gap) perform better than\n",
    "those that discard it.\n",
    "\n",
    "SimilarityEncoder is the best performer, but it is less scalable on big\n",
    "data than MinHashEncoder and GapEncoder. The most scalable encoder is\n",
    "the MinHashEncoder. GapEncoder, on the other hand, has the benefit that\n",
    "it provides interpretable features (see `sphx_glr_auto_examples_04_feature_interpretation_gap_encoder.py`)\n",
    "\n",
    "|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic vectorization\n",
    "\n",
    ".. |SV| replace::\n",
    "    :class:`~dirty_cat.SuperVectorizer`\n",
    "\n",
    ".. |OneHotEncoder| replace::\n",
    "    :class:`~sklearn.preprocessing.OneHotEncoder`\n",
    "\n",
    ".. |ColumnTransformer| replace::\n",
    "    :class:`~sklearn.compose.ColumnTransformer`\n",
    "\n",
    ".. |RandomForestRegressor| replace::\n",
    "    :class:`~sklearn.ensemble.RandomForestRegressor`\n",
    "\n",
    ".. |SE| replace:: :class:`~dirty_cat.SimilarityEncoder`\n",
    "\n",
    ".. |permutation importances| replace::\n",
    "    :func:`~sklearn.inspection.permutation_importance`\n",
    "\n",
    "Let's start again from the raw data, but this time well use an\n",
    "automated way of encoding the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = employee_salaries['data']\n",
    "y = employee_salaries['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop a few columns we don't want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(\n",
    "    [\n",
    "        'Current Annual Salary',  # Too linked with target\n",
    "        'full_name',  # Not relevant to the analysis\n",
    "        '2016_gross_pay_received',  # Too linked with target\n",
    "        '2016_overtime_pay',  # Too linked with target\n",
    "        'date_first_hired'  # Redundant with \"year_first_hired\"\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a fairly complex and heterogeneous dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge is to turn this dataframe into a form suited for\n",
    "machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the SuperVectorizer in a supervised-learning pipeline\n",
    "\n",
    "Assembling the |SV| in a pipeline with a powerful learner,\n",
    "such as gradient boosted trees, gives **a machine-learning method that\n",
    "can be readily applied to the dataframe**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The supervectorizer requires dirty_cat 0.2.0a1. If you have an older\n",
    "# version, you can install the alpha release with\n",
    "#\n",
    "#   pip install -pre dirty_cat==0.2.0a1\n",
    "#\n",
    "\n",
    "from dirty_cat import SuperVectorizer\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SuperVectorizer(auto_cast=True),\n",
    "    HistGradientBoostingRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a cross-validation to see how well this model predicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipeline, X, y, scoring='r2')\n",
    "\n",
    "import numpy as np\n",
    "print(f'{scores=}')\n",
    "print(f'mean={np.mean(scores)}')\n",
    "print(f'std={np.std(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction perform here is pretty much as good as above\n",
    "but the code here is much simpler as it does not involve specifying\n",
    "columns manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the features created\n",
    "\n",
    "Let us perform the same workflow, but without the `Pipeline`, so we can\n",
    "analyze its mechanisms along the way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_vec = SuperVectorizer(auto_cast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data between train and test, and transform them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "X_train_enc = sup_vec.fit_transform(X_train, y_train)\n",
    "X_test_enc = sup_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the features created\n",
    "Once it has been trained on data,\n",
    "we can print the transformers and the columns assignment it creates:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_vec.transformers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is being passed to the |ColumnTransformer| under the hood.\n",
    "If you're familiar with how the later works, it should be very intuitive.\n",
    "We can notice it classified the columns \"gender\" and \"assignment_category\"\n",
    "as low cardinality string variables.\n",
    "A |OneHotEncoder| will be applied to these columns.\n",
    "\n",
    "The vectorizer actually makes the difference between string variables\n",
    "(data type ``object`` and ``string``) and categorical variables\n",
    "(data type ``category``).\n",
    "\n",
    "Next, we can have a look at the encoded feature names.\n",
    "\n",
    "Before encoding:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding (we only plot the first 8 feature names):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = sup_vec.get_feature_names()\n",
    "feature_names[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it created a new column for each unique value.\n",
    "This is because we used |SE| on the column \"division\",\n",
    "which was classified as a high cardinality string variable.\n",
    "(default values, see |SV|'s docstring).\n",
    "\n",
    "In total, we have reasonnable number of encoded columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance in the statistical model\n",
    "\n",
    "In this section, we will train a regressor, and plot the feature importances\n",
    "\n",
    ".. topic:: Note:\n",
    "\n",
    "   To minimize compute time, use the feature importances computed by the\n",
    "   |RandomForestRegressor|, but you should prefer |permutation importances|\n",
    "   instead (which are less subject to biases)\n",
    "\n",
    "First, let's train the |RandomForestRegressor|,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train_enc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreiving the feature importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = regressor.feature_importances_\n",
    "std = np.std(\n",
    "    [\n",
    "        tree.feature_importances_\n",
    "        for tree in regressor.estimators_\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.title(\"Feature importances\")\n",
    "n = 20\n",
    "n_indices = indices[:n]\n",
    "labels = np.array(feature_names)[n_indices]\n",
    "plt.barh(range(n), importances[n_indices], color=\"b\", yerr=std[n_indices])\n",
    "plt.yticks(range(n), labels, size=15)\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can deduce from this data that the three factors that define the\n",
    "most the salary are: being hired for a long time, being a manager, and\n",
    "having a permanent, full-time job :).\n",
    "\n",
    "\n",
    ".. topic:: The SuperVectorizer automates preprocessing\n",
    "\n",
    "  As this notebook demonstrates, many preprocessing steps can be\n",
    "  automated by the |SV|, and the resulting pipeline can still be\n",
    "  inspected, even with non-normalized entries.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
